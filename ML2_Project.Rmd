---
title: "Analyzing indonesian rice farms"
author: "Jonas Kernebeck, Alexander Flick, Felix Lehner"
date: "07/16/2021"
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_depth: 2
---

<!-- 
packages
install.packages("plm")
install.packages("splm")
install.packages("GGally")
install.packages("heatmaply")
install.packages("tidyverse")
install.packages("corrr")
install.packages("devtools")
devtools::install_github("hadley/productplots")

-->
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)

```

\newpage

```{r imported libraries}
library(plm)
library(GGally)
library(heatmaply)
require('tidyverse')
library(tidyr)
library(ggmosaic)
library(gridExtra)
library(gam)
library(patchwork)
library(ggcorrplot)
library(kableExtra)
library(formattable)
library(ggplot2)
library(productplots)
```

```{r constants}
data("RiceFarms", package = "splm")

col_to_remove = !names(RiceFarms) %in% c("id", "noutput")
RiceFarms = RiceFarms[,col_to_remove]
```


```{r data}
# some code here 
```

# 1 Introduction

The present data set includes production data for 171 indonesian rice farms. The dataframe contains the following variables:

|  variable  |                   description                   |        expressions        |
|:----------:|:-----------------------------------------------:|:-------------------------:|
|     id     |           unique identifier for a farm          |         unique id         |
|    time    | unique identifier for a specific growing season |           1 - 6           |
|    size    |        total production area in hectares        |        0.01 - 5.322       |
|   status   |            status of property rights            | "owner", "share", "mixed" |
|  varieties |                rice seed varietes               |  "trad", "high", "mixed"  |
|    bimas   |           bimas-status of the farmers           |    "no", "yes", "mixed"   |
|    seed    |                 seed in kilogram                |        1 - 1250 kg        |
|    urea    |                 urea in kilogram                |        1 - 1250 kg        |
|  phosphate |              phosphate in kilogram              |         0 - 700 kg        |
|  pesticide |             pesticide cost in Rupiah            |        0 - 62600 r        |
|    pseed   |          price of seed in Rupiah per kg         |       40 - 375 r/kg       |
|    purea   |          price of urea in Rupiah per kg         |       50 - 100 r/kg       |
|   pphosph  |       price of phosphate in Rupiah per kg       |       60 - 120 r/kg       |
| hiredlabor |               hired labor in hours              |         1 - 4536 h        |
|  famlabor  |              family labor in hours              |         1 - 1526 h        |
|  totlabor  |      total labor (excluding harvest labor)      |         1 - 4774 h        |
|    wage    |          labor wage in Rupiah per hour          |      30 - 175.35 r/h      |
|   goutput  |            gross output of rice in kg           |       42 - 20960 kg       |
|   noutput  |        gross output minus harvesting cost       |       42 - 17610 kg       |
|    price   |       price of rough rice in Rupiah per kg      |       50 - 190 r/kg       |
|   region   |                region of the farm               |       unique region       |

As present in the table, the data set consists of 16 numeric variables and 4 categorical variables. The target variable for the regression modeling will be *goutput*, what represents the gross output of rice in *kg* for the respective rice farm.
In the following some explorative data analysis will be made to get to get a first impression of the distribution of the individual variables.

## 1.1 Numerical Variables
The following figure shows boxplots for the used materials and the prices paid for the materials of the respective rice farms. The boxplots for the materials show, that the distribution of all materials is right-skewed. The spread width of seed is the lowest, followed by phosphate and urea. Therefore *urea* also has the highest variance with 16166 followed by *phosphate* with 2264 and *seed* with 2048. The distribution of *urea* indicates that rice farms in Indonesia may use urea very different, caused by e.g. the bimas-status. The bimas program is a rice intensification program by the government to support local rice production by providing high-yield rice seeds as well as technical assistance. 
&nbsp;
If we look at the prices for phosphate *pphosph* and urea *purea*, we can see a slight left-skewed distribution with low variance (75 for *purea* and 86 for *pphosph*). In contrast to that, the prices for seeds scatter much. The distribution of *pseed* is strongly right-skewed as well as the distribution for the rice price *price*. The price for the rice also scatters, but less than *pseed*. The two prices have a correlation of 0.67. Of course, the price of seeds affects the selling price of rice. The prices may fluctuate due to seasonal or regional factors and have an impact on each other.
&nbsp;
The distribution of labor hours is also slightly skewed to the right. Overall, the dispersion is lowest for the *famlabor*. For *hiredlabor* and *totlabor* we have a similar spread, but *totlabor* has a higher level overall. This is caused by the *hiredlabor* which is a subset of *totlabor*. 


\newpage


```{r, fig.width=10, fig.height=9}

df_boxplot_materials = data.frame(
  feature=c(rep("seed", 1026), rep("urea", 1026),rep("phosphate", 1026)), 
  material=c(RiceFarms$seed, RiceFarms$urea, RiceFarms$phosphate))


bpl_materials = ggplot(df_boxplot_materials, aes(x=feature, y=material, fill=feature)) + 
  geom_boxplot() + 
  ylim(0, 600) + 
  ggtitle('Distribution of materials') + 
  theme(plot.title = element_text(hjust = 0.5))


df_boxplot_price_materials = data.frame(
  feature=c(rep("price seed", 1026), rep("price urea", 1026),rep("price phosphate", 1026), rep("price rice", 1026)), 
  rupiah_per_kg=c(RiceFarms$pseed, RiceFarms$purea, RiceFarms$pphosph, RiceFarms$price))


bpl_price_materials = ggplot(df_boxplot_price_materials, aes(x=feature, y=rupiah_per_kg, fill=feature)) + 
  geom_boxplot() + 
  ggtitle('Distribution of material prices') + 
  theme(plot.title = element_text(hjust = 0.5))
  # + ylim(0, 400)

df_boxplot_labor = data.frame(
  labor=c(rep("hired labor", 1026), rep("family labor", 1026),rep("total labor", 1026)), 
  hours=c(RiceFarms$hiredlabor, RiceFarms$famlabor, RiceFarms$totlabor))


bpl_labor = ggplot(df_boxplot_labor, aes(x=labor, y=hours, fill=labor)) + 
  geom_boxplot() + 
  ggtitle('Distribution of labor hours') + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  ylim(0,500)


grid.arrange(bpl_materials, bpl_price_materials, bpl_labor, ncol=1, nrow =3)

```

\newpage

## 1.1 Categorical Variables

The following mosaic plot shows the distribution of of the categorical variables *varietes*, *region* and *bimas*. Overall, all regions are roughly equally represented in the data set. We can detect, that most of the farmers with the bimas status *yes* and *mixed* are located in the region *ciwangi*. The distribution of the different varieties is strongly dependent on the region. While the *high* varieties have the biggest share in the regions *wargabinangun* and *langan*, the *traditional* varieties are dominating the regions *gunungwangi*, *malausma* and *ciwangi*. The *mixed* varities are only used slightly in all regions.
\
\
\


```{r, fig.width=7, fig.height=5}

df_cat = RiceFarms[,c("region", "varieties", "bimas")]

test = ggplot(df_cat) +
  ggtitle("Mosaic Plot for varieties, region and bimas") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_mosaic(aes(x = product(varieties, region), fill=bimas, offset = 0.2))

breaks = ggplot_build(test)$layout$panel_params[[1]]$x$get_breaks()
labels=c("wargabinangun","", "","","langan", "","gunungwangi","", "",
         "malausma","", "","sukaambit","", "",
         "ciwangi","","")

ggplot(df_cat) +
  ggtitle("Mosaic Plot for varieties, region and bimas") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_mosaic(aes(x = product(varieties, region), fill=bimas, offset = 0.2)) +
  scale_x_productlist(breaks=breaks, labels=labels) + 
  xlab("region")
  

```

\
\
\

To test wheter the categorical variables have impact on our target variable *goutput*, one- and two-sided anovas are performed. The results of these are summarized in the following table:
\
\


|         formula        | F-value |  p-value | significant |
|:----------------------:|:-------:|:--------:|:-----------:|
|         region         |  22.981 |  < 2e-16 |     yes     |
|        varieties       |  11.764 | 8.94e-06 |     yes     |
|          bimas         |  14.817 | 4.57e-07 |     yes     |
|     region+varietes    |  3.847  | 3.96e-05 |     yes     |
|      region+bimas      |  5.651  | 2.94e-08 |     yes     |
|     varieties+bimas    |  0.791  |   0.531  |      no     |
| region+varieties+bimas |  0.860  |   0.580  |      no     |



The anova outputs show, that all of the categorical variables have a significant effect on *goutput*. The null hypothesis, that the mean of *goutput* is the same across the groups is rejected. The results of the two-sided anovas also show a significant interaction effect on *goutput*. While the interaction effect from the *region* with *varieties* and *bimas* is significant, the interaction effect of *varieties* and *bimas* and the interaction effect of all three variables is not.

## 1.3 Variable selection and transformation

The performance of the regression modeling is highly dependent of the variable selection and transformation. Therefore a suitable choice is very important. 
The variable *noutput* is a linear transformation of *goutput* as it represents *goutput* decreased by the harvesting costs. Therefore it is not used for the modeling because it would violate the multicollinearity assumption. \
The variable *size* also correlates *strongly* with the target variable. This can be intuitively explained by the fact that a larger rice field naturally always produces a higher yield. Since the variables *seed*, *urea*, *phosphate* and *pesticide* are dependent on size, they are transformed into per-hectare sizes by dividing them with the respective hectare size of the farm. The *size* variable is not used for further modeling. \
The variables *famlabor* and *hiredlabor* are subsets of the variable *totlabor* and are therefore transformed into the share of *totlabor* by dividing them with the amount of *totlabor*. The variable *totlabor* is after that transformed to a per-hectare size by dividing it with the *size*.
The variable *wage* follows a bimodal distribution. Therefore it is transformed into a binary variable, which indicates if the respective value is over or under 100. 

## 1.4 Model evaluation

The data set will be splitted in 60-20-20 parts, where 60% of the data is used for training the model, and 20% for testing and validating respectively. In the modeling part, also cross-validation is used. To evaluate the models and compare them, different metrics will be used. The numeric metrics used are the *MSE*, which stands for the mean squared error and the *AIC*, which stands for the Akaike information criterion. Beside these metrics, also graphical analysis plots like a residual plots are used for evaluation.

```{r}
#reorder levels
factor_bimas <- c("no", "mixed", "yes")
RiceFarms$bimas <- factor(RiceFarms$bimas, levels = factor_bimas)

factor_varieties <- c("trad", "mixed", "high")
RiceFarms$varieties <- factor(RiceFarms$varieties, levels = factor_varieties)
```

3 Outliers most likely due to typos for observation 110, 947 and 1004

```{r echo=FALSE}
#outliers
#RiceFarms[RiceFarms$seed>1000,]
#RiceFarms[RiceFarms$id==102220,]
RiceFarms$seed[110] <- 125 #instead of 1250

#RiceFarms[RiceFarms$pesticide>60000,]
#RiceFarms[RiceFarms$id==607168,]
RiceFarms$pesticide[947] <- 6260 #instead of 62600

#outlier?
#RiceFarms[RiceFarms$totlab_size>14000,]
#RiceFarms[RiceFarms$id==609241,]
RiceFarms$size[1004] <- 0.1 #instead of 0.01
```


```{r}
#divide by size
RiceFarms$seed_size <- RiceFarms$seed/RiceFarms$size
RiceFarms$phosph_size <- RiceFarms$phosphate/RiceFarms$size
RiceFarms$urea_size <- RiceFarms$urea/RiceFarms$size
RiceFarms$totlab_size <- RiceFarms$totlabor/RiceFarms$size
RiceFarms$pest_size <- RiceFarms$pesticide/RiceFarms$size
```


```{r}
RiceFarms$fam_ratio <- RiceFarms$famlabor/RiceFarms$totlabor
```


```{r}
#wage
#plot(wage,goutput)
RiceFarms$wage_cat <- ifelse(RiceFarms$wage > 100, "<100", ">100")
RiceFarms$wage_cat <- factor(RiceFarms$wage_cat)
```


```{r}
#Split the data into a 60-20-20 split for training, validation and testing.
set.seed(20211207)
n <- nrow(RiceFarms)
train <- sample(1:n,0.8*n)
test <- setdiff(1:n,train)
set.seed(20211207)
val <- sample(train,length(test))
train <- setdiff(train,val)
```

```{r}
MSE <- function(model, data, split=train){
  pred.split <- predict(model, newdata = data[split,])
  return(mean((exp(pred.split)-RiceFarms$goutput[split])^2))
}
```

\newpage



# 2 First Model

\newpage

# 3 Second Model
## GAM (Generalized Additive Model)

```{r}
#size
gam1 <- gam(log(goutput)~s(size), data = RiceFarms[train,])
gam2 <- gam(log(goutput)~s(log(size)), data = RiceFarms[train,])
```


```{r}
#par(mfrow=c(1,1))
#plot.Gam(gam2, residuals = TRUE, col="lightblue")
```

```{r}
#labour
gam3 <- gam(log(goutput)~s(log(size))+s(log(totlab_size)), data = RiceFarms[train,])
gam4 <- gam(log(goutput)~s(log(size))+s(totlab_size), data = RiceFarms[train,])

par(mfrow=c(1,2))
plot.Gam(gam3, residuals = TRUE, col="lightblue")
```
**Explanation:**
The left-hand panel indicates that holding totlab_size fixed, goutput increases with size.
The right-hand panel indicates that holding size fixed, goutput increases drasticall with the increased proportion of labour per size up to a proportion of 500 h / hectar and then flattens out.


```{r}
#urea
gam5 <-  gam(log(goutput)~
               s(log(size))+
               s(log(totlab_size))+
               s(log(urea_size)), data = RiceFarms[train,])

gam5.1 <- gam(log(goutput)~
                s(log(size))+
                s(log(totlab_size))+
                s(urea_size), data = RiceFarms[train,])

#anova(gam4, gam5, gam5.1) #use gam5 with log(urea) slightly better

#par(mfrow=c(1,3))
#plot.Gam(gam5, residuals = TRUE, col="lightblue")
```

```{r}
#phosphor
gam6 <- gam(log(goutput)~
              s(log(size))+
              s(log(totlab_size))+
              s(log(urea_size))+
              s(log(phosph_size+1)), data = RiceFarms[train,])

gam6.1 <- gam(log(goutput)~
              s(log(size))+
              s(log(totlab_size))+
              s(log(urea_size))+
              s(phosph_size), data = RiceFarms[train,])

#anova(gam5,gam6, gam7) #use gam6
```

```{r}
#seed
gam8 <- gam(log(goutput)~
              s(log(size))+
              s(log(totlab_size))+
              s(log(urea_size)) +
              s(log(phosph_size+1))+
              s(log(seed_size)), data = RiceFarms[train,])

gam9 <- gam(log(goutput)~
              s(log(size))+
              s(log(totlab_size))+
              s(log(urea_size)) +
              s(log(phosph_size+1))+
              s(seed_size), data = RiceFarms[train,])

#anova(gam6, gam8, gam9) #use gam9
```

```{r}
#pesticide
gam10 <- gam(log(goutput)~
              s(log(size))+
              s(log(totlab_size))+
              s(log(urea_size)) +
              s(log(phosph_size+1))+
              s(seed_size)+
              s(pest_size), data = RiceFarms[train,])

#tail(summary(gam10)$parametric.anova$Pr, n=2)[1]
```

```{r}
gam10.1 <- gam(log(goutput)~
               s(log(size))+
               s(log(totlab_size))+
               s(log(urea_size)) +
               s(log(phosph_size+1))+
               s(seed_size)+
               s(pest_size, df=1), data = RiceFarms[train,])

#tail(summary(gam10.1)$parametric.anova$Pr, n=2)[1]
```

```{r}
#add price
gam11 <- gam(log(goutput)~
               s(log(size))+
               s(log(totlab_size))+
               s(log(urea_size)) +
               s(log(phosph_size+1))+
               s(seed_size)+
               s(pest_size)+
               s(price), data = RiceFarms[train,])

#anova(gam10,gam11)
```

```{r}
#add fam_ratio
gam12 <- gam(log(goutput)~
                 s(log(size))+
                 s(log(totlab_size))+
                 s(log(urea_size)) +
                 s(log(phosph_size+1))+
                 s(seed_size)+
                 s(pest_size)+
                 s(price)+
                 s(fam_ratio), data = RiceFarms[train,])

gam12.1 <- gam(log(goutput)~
                 s(log(size))+
                 s(log(totlab_size))+
                 s(log(urea_size)) +
                 s(log(phosph_size+1))+
                 s(seed_size)+
                 s(pest_size)+
                 s(price)+
                 s(fam_ratio, df=13), data = RiceFarms[train,])

#par(mfrow=c(2,4))
#plot.Gam(gam12.1, residuals = TRUE, col="lightblue")

#tail(summary(gam13)$parametric.anova$Pr, n=2)[1]
#anova(gam12.2,gam13)
```



```{r}
#add price info
gam12.2 <- gam(log(goutput)~
                 s(log(size))+
                 s(log(totlab_size))+
                 s(log(urea_size)) +
                 s(log(phosph_size+1))+
                 s(seed_size)+
                 s(pest_size)+
                 s(price)+
                 #s(fam_ratio)+
                 s(pseed), data = RiceFarms[train,])

gam12.3 <- gam(log(goutput)~
                 s(log(size))+
                 s(log(totlab_size))+
                 s(log(urea_size)) +
                 s(log(phosph_size+1))+
                 s(seed_size)+
                 s(pest_size)+
                 s(price)+
                 #s(fam_ratio)+
                 s(pphosph), data = RiceFarms[train,])

gam12.5  <- gam(log(goutput)~
                 s(log(size))+
                 s(log(totlab_size))+
                 s(log(urea_size)) +
                 s(log(phosph_size+1))+
                 s(seed_size)+
                 s(pest_size)+
                 s(price)+
                 #s(fam_ratio)+
                 s(pphosph)+
                 s(purea), data = RiceFarms[train,])

#tail(summary(gam13)$parametric.anova$Pr, n=2)[1]
#anova(gam12.2,gam13)
```

```{r}
#add wage
gam13 <- gam(log(goutput)~
               s(log(size))+
               s(log(totlab_size))+
               s(log(urea_size)) +
               s(log(phosph_size+1))+
               s(seed_size)+
               s(pest_size)+
               s(price)+
               #s(fam_ratio)+
               s(pphosph)+
               s(wage), data = RiceFarms[train,])

gam13.2 <- gam(log(goutput)~
                 s(log(size))+
                 s(log(totlab_size))+
                 s(log(urea_size)) +
                 s(log(phosph_size+1))+
                 s(seed_size)+
                 s(pest_size)+
                 s(price)+
                # s(fam_ratio)+
                 s(pphosph)+
                 wage_cat, data = RiceFarms[train,])

#tail(summary(gam12.2)$parametric.anova$Pr, n=2)[1]
```

```{r}
#bimas
gam14 <- gam(log(goutput)~
               s(log(size))+
               s(log(totlab_size))+
               s(log(urea_size)) +
               s(log(phosph_size+1))+
               s(seed_size)+
               s(pest_size)+
               s(price)+
               #s(fam_ratio)+
               s(pphosph)+
               wage_cat+
               bimas, data = RiceFarms[train,])

#summary(gam14)
#tail(summary(gam14)$parametric.anova$Pr, n=2)[1]
```

```{r}
#varieties
gam15 <- gam(log(goutput)~
               s(log(size))+
               s(log(totlab_size))+
               s(log(urea_size)) +
               s(log(phosph_size+1)) +
               s(seed_size)+
               s(pest_size)+
               s(price)+
               #s(fam_ratio)+
               s(pphosph)+
               wage_cat +
               bimas+
               varieties, data = RiceFarms[train,])

#tail(summary(gam15)$parametric.anova$Pr, n=2)[1]
```

```{r}
#status

gam16 <- gam(log(goutput)~
               s(log(size))+
               s(log(totlab_size))+
               s(log(urea_size)) +
               s(log(phosph_size+1))+
               s(seed_size)+
               s(pest_size)+
               s(price)+
               #s(fam_ratio)+
               s(pphosph)+
               wage_cat +
               bimas+
               status, data = RiceFarms[train,])

#tail(summary(gam16)$parametric.anova$Pr, n=2)[1]
```

```{r}
#region
gam17 <- gam(log(goutput)~
               s(log(size))+
               s(log(totlab_size))+
               s(log(urea_size)) +
               s(log(phosph_size+1))+
               s(seed_size)+
               s(pest_size)+
               s(price)+
               #s(fam_ratio)+
               s(pphosph)+
               wage_cat +
               bimas +
               region, data = RiceFarms[train,])

#tail(summary(gam17)$parametric.anova$Pr, n=2)[1]
#anova(gam14,gam17)
```

```{r}
#adding purea once again
gam17.2 <- gam(log(goutput)~
               s(log(size))+
               s(log(totlab_size))+
               s(log(urea_size)) +
               s(log(phosph_size+1))+
               s(seed_size)+
               s(pest_size)+
               s(price)+
               #s(fam_ratio)+
               s(pphosph)+
               wage_cat +
               bimas +
               #region +
               s(purea), data = RiceFarms[train,])

#adding varieties once again
gam17.4 <- gam(log(goutput)~
               s(log(size))+
               s(log(totlab_size))+
               s(log(urea_size)) +
               s(log(phosph_size+1))+
               s(seed_size)+
               s(pest_size)+
               s(price)+
               #s(fam_ratio)+
               s(pphosph)+
               wage_cat +
               bimas +
               #region +
               s(purea)+
               varieties, data = RiceFarms[train,])

```

## GAM Comparison

**table for model selection:** The following table summarizes the variable selection process for the final GAM model. Starting from the top of the table we add for each grouped row in the table another variable with different representations of the variable for example checking whether log transformation yields any better results than using the variable as is. The results are mainly compared by using the p-value from the model summary, which is telling if the variable is significant important. We will use a p-value of 5% for the evaluation of variable significance. To compare models we will use the deviance. In special cases additional anova tests are performed to compare larger models with smaller ones. In addition we list other metrics like MSE on the training and validation data as well as AIC. For each grouped row, the last model is the chosen model for further analysis.

Forward selection (from James p. 79) : We begin with a model, that contains the variable with highest correlation to our dependent variable goutput, which is size. We then add different representations of one variable and add those to the model, which result in the lowest deviance for the new two-variable model. This approach is continued until all variables have been tried out. Forward selection is a greedy approach, and might include variables early that later become redundant.


```{r }
#results='asis'
options(tinytex.verbose = TRUE)

###############
#table for model selection
#https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html#Overview

gams <- list(gam17.4,gam17.2, gam17,gam16, gam15, gam14, gam13.2, gam13, gam12.5, gam12.3,gam12.2, gam12, gam11, gam10.1, gam10, gam9, gam8 , gam6, gam6.1,  gam5, gam5.1,  gam3, gam4, gam2, gam1)
gams <- rev(gams)

l <- length(gams)
var <- rep(NA, l)
df <- rep(NA, l)
MSE.train <- rep(NA, l)
MSE.val <- rep(NA, l)
dev <- rep(NA, l)
aic <- rep(NA, l)
p_val_p <- rep(NA, l)
p_val_np <- rep(NA, l)
df_np <- rep(NA, l)

for (i in 1:l){
  var[i] <- tail(names(coefficients(gams[[i]])), n=1)
  df[i] <-  round(df.residual(gams[[i]]))
  MSE.train[i] <- round(MSE(gams[[i]], RiceFarms, train))
  MSE.val[i] <- round(MSE(gams[[i]], RiceFarms, val))
  dev[i] <- round(deviance(gams[[i]]),1)
  aic[i] <- round(AIC(gams[[i]]),1)
  p_val_p[i] <- round(tail(summary(gams[[i]])$parametric.anova$Pr, n=2)[1],4)
  p_val_np[i] <- round(tail(summary(gams[[i]])$anova$Pr, n=1)[1],4)
  df_np[i] <- tail(summary(gams[[i]])$anova$`Npar Df`,n=1)
}

model_perf <- data.frame(var, df, MSE.train, MSE.val, dev, aic, p_val_p, p_val_np, df_np)
#colnames(model_perf) <- c("var","df","MSE.train","MSE.val","dev","aic","p_val_p", "p_val_np", "df_np")

model_perf$var[17]<- "s(pphosph)+s(purea)"
model_perf$var[20:23] <- c("bimas", "bimas+varieties", "bimas+status", "bimas+region")
model_perf$var[25] <- "s(purea)+varieties"

kbl(model_perf, caption = "GAM comparison for variable selection") %>%
  kable_paper("hover", full_width = FALSE) %>%
  pack_rows("size", 1, 2) %>%
  pack_rows("size+labour", 3, 4) %>%
  pack_rows("size+labour+urea", 5, 6) %>%
  pack_rows("size+labour+urea+phosphor", 7, 8) %>%
  pack_rows("size+labour+urea+phosphor+seed", 9, 10) %>%
  pack_rows("size+labour+urea+phosphor+seed+pesticide", 11, 12) %>%
  pack_rows("size+labour+urea+phosphor+seed+pesticide+price", 13, 13) %>%
  pack_rows("size+labour+urea+phosphor+seed+pesticide+price+family_labour", 14, 14) %>%
  pack_rows("size+labour+urea+phosphor+seed+pesticide+price+price_info", 15, 17) %>%
  pack_rows("size+labour+urea+phosphor+seed+pesticide+price+price_info+wage", 18, 19) %>%
  pack_rows("size+labour+urea+phosphor+seed+pesticide+price+price_info+wage+categorical", 20, 23) %>%
  pack_rows("size+labour+urea+phosphor+seed+pesticide+price+price_info+wage+categorical+excluded", 24, 25) %>%
  landscape()

```

**Table columns:**

* var: the variable that is added
* df: degrees of freedom 
* MSE.train: MSE on training data
* MSE.val: MSE on validation data
* dev: residual deviance (goodness of fit)
* aic: Akaike information criterion
* p_val_p: parametric p-value for last added variable
* p_val_np: non-parametric p-value for last added variable
* df_np: non-parametric degrees of freedom for last added variable

**Variable selection explanation:**

* size, labour, and urea: we will use logarithm of these variables, because of a smaller deviance
* phosphor: this variable has lots of zeros as values. So we can not use directly log transformation because log of 0 is -inf. log(x+1) transformation is the best way to avoid errors created  by log transformation and is widely used among data scientists. So we will use this approach. We will use logarithm of phosph_size, because of a smaller deviance.
* seed: we will use seed as is, because of a smaller deviance.
* pesticide: non-parametric p-value is > 0.05 so we decrease df to achieve more suitable fit.
* price, family labour: Both variables are significant important for the model.
* material prices: 
    * pseed: p-value > 0.05, thus we do not use this variable
    * pphosph: p-value < 0.05
    * pphosph + purea: p-value < 0.05, but the anova test comparing smaller including only pphosph with larger model pphosp + purea yields a p-value of 
* wage:
* categorical variables: 
    + bimas and bimas+region: p-value > 0.05, 
    + bimas+varieties and bimas+status: p-value < 0.05 
* final model: we check again for excluded variables after some more variables have been added if the results change. purea has a p-value of 0.05 and performing an anova test for varieties we can see that there is a significant difference between the two models. 

```{r }
#Anova test
anova(gam17.2,gam17.4)
```
\newpage

```{r}
gams <- list(gam17.4,gam17.2, gam17, gam14, gam13.2,gam12.3,gam12, gam11, gam10, gam9, gam6, gam5, gam3, gam2)
gams <- rev(gams)

l <- length(gams)
var <- rep(NA, l)
MSE.train <- rep(NA, l)
MSE.val <- rep(NA, l)
dev <- rep(NA, l)

for (i in 1:l){
  var[i] <- tail(names(coefficients(gams[[i]])), n=1)
  MSE.train[i] <- round(MSE(gams[[i]], RiceFarms, train))
  MSE.val[i] <- round(MSE(gams[[i]], RiceFarms, val))
  dev[i] <- deviance(gams[[i]])
}

model_perf <- data.frame(MSE.train, MSE.val, dev, var,row.names = var)

df.long <- pivot_longer(model_perf, cols=1:3, names_to = "metric", values_to = "value")
#make var ordered factor

df.long$var <- factor(df.long$var, levels =var)

mse_plot <- ggplot(df.long[df.long$metric!="dev",])+
  aes(x= var, y=value, group=metric, color = metric)+
  geom_line()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        axis.title.x = element_blank(), legend.position = c(0.8, 0.8))

dev_plot <- ggplot(df.long[df.long$metric=="dev",])+
  aes(x=var, y=value, group=1)+
  geom_line()+
  ylab("deviance")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        axis.title.x = element_blank())
  
patch1 <- mse_plot + dev_plot

patch1 + plot_annotation(
  title = 'Model performance'
)
```

```{r fig.height=3.5, fig.align = "center"}
#library(ggfortify)
#autoplot(gam17.4)

ylim <- c(min(residuals(gam1)), max(residuals(gam1)))
xlim <- c(min(fitted(gam17.4)), max(fitted(gam17.4)))

#par(mfrow=c(1,3))
#plot(fitted(gam1),residuals(gam1))
#plot(fitted(gam2),residuals(gam2), ylim=ylim)
#plot(fitted(gam17.4),residuals(gam17.4), ylim=ylim)

gam1_res <- data.frame(fitted=fitted(gam1),residuals=residuals(gam1))
gam2_res <- data.frame(fitted=fitted(gam2),residuals=residuals(gam2))
gam17.4_res <- data.frame(fitted=fitted(gam17.4),residuals=residuals(gam17.4))

gam1_res_plot <- ggplot(gam1_res)+
  aes(x=fitted,y=residuals)+
  xlim(xlim)+
  geom_point(alpha = 3/10)+
  theme(plot.subtitle=element_text(size=7))+
  labs(subtitle = "s(log(size))")

  #labs(title = "Fitted vs. Residuals", subtitle = expression(atop("1st model", paste("s(log(size))"))))

gam2_res_plot <- ggplot(gam2_res)+
  aes(x=fitted,y=residuals)+
  ylim(ylim) +
  xlim(xlim)+
  geom_point(alpha = 3/10) +
  theme(plot.subtitle=element_text(size=7))+
  labs(subtitle = "s(log(size)) + s(log(totlab_size))")

gam17.4_res_plot <- ggplot(gam17.4_res)+
  aes(x=fitted,y=residuals)+
  ylim(ylim) +
  xlim(xlim) +
  geom_point(alpha = 3/10) +
  theme(plot.subtitle=element_text(size=7))+
  labs(subtitle = "Final model")
  

patch <- gam1_res_plot+gam2_res_plot+gam17.4_res_plot

patch + plot_annotation(
  title = 'Residual comparison'
)

```
\newpage
## Final GAM

```{r}
#summary(gam17.4)$call
formula(gam17.4)
#summary(gam17.4)$dispersion
#summary(gam17.4)$df
#summary(gam17.4)$deviance.resid
#summary(gam17.4)$deviance
```
**R-squared (R²)**: is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. Essentially, an R-Squared value of 0.9 would indicate that 90% of the variance of the dependent variable being studied is explained by the variance of the independent variable.

$R^2 = 1- \frac{Unexplained\:Variation}{Total\:Variation}$

```{r}
r_sq <- function(model){
  UEV <- length(train)*MSE(gam17.4, RiceFarms)
  TV <- sum((RiceFarms$goutput[train]-mean(RiceFarms$goutput[train]))^2)
  return(1-UEV/TV)
}
```

R² = `r r_sq(gam17.4)`

**Adjusted R-Squared**: The adjusted R-squared compares the descriptive power of regression models that include diverse numbers of predictors. Every predictor added to a model increases R-squared and never decreases it. Thus, a model with more terms may seem to have a better fit just for the fact that it has more terms, while the adjusted R-squared compensates for the addition of variables and only increases if the new term enhances the model above what would be obtained by probability and decreases when a predictor enhances the model less than what is predicted by chance.

Source: https://www.investopedia.com/terms/r/r-squared.asp
https://www.researchgate.net/post/How-can-I-get-the-adjusted-r-squared-value-of-GAM-model

$adjR^2 = 1- \frac{(1-R^2)*(n-1)}{n-p-1}$

n = total sample size
p = number of predictors

```{r}
r_sq_adj <- function(model){
  R2adj <- 1- ((1 - r_sq(model)) * (length(model$y) - 1)/(length(model$y) - length(model$coefficients) - 1))
  return(R2adj)
}
```

adjR²= `r r_sq_adj(gam17.4)`

\newpage
**Final GAM visualization**
```{r fig.height=8, fig.align='center'}

gam_num <- c("s(log(size))", "s(log(totlab_size))", "s(log(urea_size))" , "s(log(phosph_size + 1))" , "s(seed_size)", "s(pest_size)" , "s(price)" , "s(pphosph)", "s(purea)")

#gam_cat <-  c("wage_cat", "bimas", "region", "varieties")
gam_cat <-  c("wage_cat", "bimas", "varieties")

par(mfrow=c(7,2), 
    oma = c(5,4,1,1) + 0.1,
    mar = c(2,3.5,2,2) + 0.1,
    mgp = c(2, 0.5, 0)) #The default is c(3, 1, 0).
plot.Gam(gam17.4, residuals = TRUE, se=TRUE, terms = gam_num  , col="lightblue", cex.lab = 0.8)

for(i in 1:length(gam_cat)){
  plot.Gam(gam17.4, residuals = TRUE, se=TRUE, terms = gam_cat[i] , col="lightblue", cex.lab = 0.8, xlab="")
  title(xlab=gam_cat[i], line=0.5, cex.lab=1.2)
}

```

```{r}
```
\newpage

# 4 Comparision

\newpage

# 5 Conclusion

\newpage